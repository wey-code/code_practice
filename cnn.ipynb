{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wey-code/code_practice/blob/master/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYi3Jmmsc7ch"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/Hashing\")\n",
        "\n",
        "#!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip # 下載資料集\n",
        "#!unzip food-11.zip # 解壓縮\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bGm0wwydx0a"
      },
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import pandas as pd\r\n",
        "from torch.utils.data import DataLoader,Dataset\r\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCQEAvLec7co"
      },
      "source": [
        "将图片读入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSJGW3koc7cp"
      },
      "source": [
        "def readfile(path,label):\n",
        "    image_dir = sorted(os.listdir(path))\n",
        "    x = np.zeros((len(image_dir),128,128,3),dtype=np.uint8)\n",
        "    y = np.zeros((len(image_dir)),dtype=np.uint8)\n",
        "    for i, file in enumerate(image_dir):\n",
        "        img = cv2.imread(os.path.join(path,file))\n",
        "        x[i, :, :] = cv2.resize(img,(128, 128))\n",
        "        if label:\n",
        "            y[i] = int(file.split(\"_\")[0])\n",
        "    if label:\n",
        "        return x,y\n",
        "    else:\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEKgUCmEc7cp",
        "outputId": "c8484cd0-b87d-4ac6-9ac6-f3a109aae711"
      },
      "source": [
        "workspace_dir = './food-11'\n",
        "print(\"reading data\")\n",
        "train_x,train_y = readfile(os.path.join(workspace_dir,\"training\"),True)\n",
        "print(\"size of training data = {}\".format(len(train_x)))\n",
        "val_x,val_y = readfile(os.path.join(workspace_dir,\"validation\"),True)\n",
        "print(\"size of validation data = {}\".format(len(val_x)))\n",
        "test_x = readfile(os.path.join(workspace_dir,\"testing\"),False)\n",
        "print(\"size of testing data = {}\".format(len(test_x)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading data\n",
            "size of training data = 9866\n",
            "size of validation data = 3430\n",
            "size of testing data = 3347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM-wf3f6c7cr"
      },
      "source": [
        "使用dataset来打包数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR8v0zHTc7cs"
      },
      "source": [
        "#training时候 通过翻转之类做数据扩增 data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class ImgDataset(Dataset):\n",
        "    def __init__(self,x,y=None, transform=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        if y is not None:\n",
        "            self.y = torch.LongTensor(y)\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self,index):\n",
        "        X = self.x[index]\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        if self.y is not None:\n",
        "            Y = self.y[index]\n",
        "            return X,Y\n",
        "        else:\n",
        "            return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpLh2Ubyc7ct"
      },
      "source": [
        "batch_size = 128\n",
        "train_set = ImgDataset(train_x, train_y, train_transform)\n",
        "val_set = ImgDataset(val_x, val_y, test_transform)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJYzGj31c7ct"
      },
      "source": [
        "开始建立模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e8fop09c7ct"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "                super(Classifier,self).__init__()\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "        # input 維度 [3, 128, 128]\n",
        "                self.cnn = nn.Sequential(\n",
        "                    nn.Conv2d(3,64,3,1,1), #[64,128,128]\n",
        "                    nn.BatchNorm2d(64),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2,2,0),#[64,64,64]\n",
        "\n",
        "                    nn.Conv2d(64,128,3,1,1), #[128,64,64]\n",
        "                    nn.BatchNorm2d(128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2,2,0),#[128,32,32]\n",
        "\n",
        "                    nn.Conv2d(128,256,3,1,1), #[256,32,32]\n",
        "                    nn.BatchNorm2d(256),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2,2,0),#[256,16,16]\n",
        "\n",
        "                    nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
        "                    nn.BatchNorm2d(512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
        "\n",
        "                    nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
        "                    nn.BatchNorm2d(512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]   \n",
        "            )\n",
        "                self.fc =  nn.Sequential(\n",
        "                    nn.Linear(512*4*4,1024),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(1024,512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(512,11),\n",
        "            )\n",
        "            \n",
        "    def forward(self,x):\n",
        "            out = self.cnn(x)\n",
        "            out = out.view(out.size()[0],-1)\n",
        "            return self.fc(out)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8vgXerXc7cu"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz4BofaOc7cu",
        "outputId": "38de4744-b720-49cf-bff5-1dd94fd72989"
      },
      "source": [
        "model = Classifier().cuda()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "num_epoch = 30\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    model.train()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        train_pred = model(data[0].cuda())\n",
        "        batch_loss = loss(train_pred,data[1].cuda())\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "                val_pred = model(data[0].cuda())\n",
        "                batch_loss = loss(val_pred, data[1].cuda())\n",
        "\n",
        "                val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "            #將結果 print 出來\n",
        "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
        "                (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "                 train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/030] 17.25 sec(s) Train Acc: 0.253902 Loss: 0.033449 | Val Acc: 0.289796 loss: 0.038061\n",
            "[002/030] 17.32 sec(s) Train Acc: 0.373100 Loss: 0.028208 | Val Acc: 0.314577 loss: 0.034175\n",
            "[003/030] 17.37 sec(s) Train Acc: 0.430063 Loss: 0.025858 | Val Acc: 0.435860 loss: 0.025331\n",
            "[004/030] 17.46 sec(s) Train Acc: 0.470809 Loss: 0.023840 | Val Acc: 0.438484 loss: 0.026522\n",
            "[005/030] 17.40 sec(s) Train Acc: 0.499392 Loss: 0.022754 | Val Acc: 0.503499 loss: 0.022996\n",
            "[006/030] 17.39 sec(s) Train Acc: 0.526150 Loss: 0.021296 | Val Acc: 0.385131 loss: 0.033345\n",
            "[007/030] 17.29 sec(s) Train Acc: 0.559497 Loss: 0.020070 | Val Acc: 0.495918 loss: 0.023542\n",
            "[008/030] 17.34 sec(s) Train Acc: 0.579161 Loss: 0.018958 | Val Acc: 0.559475 loss: 0.020949\n",
            "[009/030] 17.38 sec(s) Train Acc: 0.609467 Loss: 0.017740 | Val Acc: 0.506706 loss: 0.023654\n",
            "[010/030] 17.30 sec(s) Train Acc: 0.621123 Loss: 0.017067 | Val Acc: 0.427697 loss: 0.031007\n",
            "[011/030] 17.37 sec(s) Train Acc: 0.644841 Loss: 0.016178 | Val Acc: 0.545481 loss: 0.021395\n",
            "[012/030] 17.35 sec(s) Train Acc: 0.654977 Loss: 0.015424 | Val Acc: 0.600583 loss: 0.019042\n",
            "[013/030] 17.39 sec(s) Train Acc: 0.679607 Loss: 0.014428 | Val Acc: 0.492420 loss: 0.026161\n",
            "[014/030] 17.35 sec(s) Train Acc: 0.689337 Loss: 0.013898 | Val Acc: 0.603499 loss: 0.018835\n",
            "[015/030] 17.29 sec(s) Train Acc: 0.714373 Loss: 0.013055 | Val Acc: 0.576093 loss: 0.022587\n",
            "[016/030] 17.30 sec(s) Train Acc: 0.724103 Loss: 0.012505 | Val Acc: 0.611370 loss: 0.018838\n",
            "[017/030] 17.34 sec(s) Train Acc: 0.734036 Loss: 0.011860 | Val Acc: 0.593878 loss: 0.020689\n",
            "[018/030] 17.30 sec(s) Train Acc: 0.751976 Loss: 0.011129 | Val Acc: 0.409038 loss: 0.037649\n",
            "[019/030] 17.35 sec(s) Train Acc: 0.751064 Loss: 0.011253 | Val Acc: 0.557726 loss: 0.024058\n",
            "[020/030] 17.32 sec(s) Train Acc: 0.780357 Loss: 0.009910 | Val Acc: 0.638776 loss: 0.018308\n",
            "[021/030] 17.32 sec(s) Train Acc: 0.784310 Loss: 0.009711 | Val Acc: 0.606706 loss: 0.019903\n",
            "[022/030] 17.37 sec(s) Train Acc: 0.807825 Loss: 0.008734 | Val Acc: 0.602041 loss: 0.024045\n",
            "[023/030] 17.28 sec(s) Train Acc: 0.809548 Loss: 0.008523 | Val Acc: 0.671137 loss: 0.017356\n",
            "[024/030] 17.33 sec(s) Train Acc: 0.832556 Loss: 0.007667 | Val Acc: 0.594461 loss: 0.026400\n",
            "[025/030] 17.28 sec(s) Train Acc: 0.835800 Loss: 0.007424 | Val Acc: 0.644023 loss: 0.020024\n",
            "[026/030] 17.32 sec(s) Train Acc: 0.853233 Loss: 0.006654 | Val Acc: 0.647813 loss: 0.020374\n",
            "[027/030] 17.34 sec(s) Train Acc: 0.857288 Loss: 0.006414 | Val Acc: 0.667347 loss: 0.019831\n",
            "[028/030] 17.24 sec(s) Train Acc: 0.868032 Loss: 0.005854 | Val Acc: 0.655977 loss: 0.020699\n",
            "[029/030] 17.37 sec(s) Train Acc: 0.871072 Loss: 0.005748 | Val Acc: 0.673761 loss: 0.019214\n",
            "[030/030] 17.31 sec(s) Train Acc: 0.873809 Loss: 0.005609 | Val Acc: 0.636152 loss: 0.025607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hHuLcjvsq-i"
      },
      "source": [
        "得到较好的超参数之后    \r\n",
        "将所有数据混合在一起进行训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-IxOXyroBaW",
        "outputId": "d014f3cd-50c3-4a1f-8a13-128add56a805"
      },
      "source": [
        "train_val_x = np.concatenate((train_x, val_x), axis=0)\r\n",
        "train_val_y = np.concatenate((train_y, val_y), axis=0)\r\n",
        "train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)\r\n",
        "train_val_loader = DataLoader(train_val_set, batch_size=batch_size, shuffle=True)\r\n",
        "\r\n",
        "model_best = Classifier().cuda()\r\n",
        "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\r\n",
        "optimizer = torch.optim.Adam(model_best.parameters(), lr=0.001) # optimizer 使用 Adam\r\n",
        "num_epoch = 30\r\n",
        "\r\n",
        "for epoch in range(num_epoch):\r\n",
        "    epoch_start_time = time.time()\r\n",
        "    train_acc = 0.0\r\n",
        "    train_loss = 0.0\r\n",
        "\r\n",
        "    model_best.train()\r\n",
        "    for i, data in enumerate(train_val_loader):\r\n",
        "        optimizer.zero_grad()\r\n",
        "        train_pred = model_best(data[0].cuda())\r\n",
        "        batch_loss = loss(train_pred, data[1].cuda())\r\n",
        "        batch_loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\r\n",
        "        train_loss += batch_loss.item()\r\n",
        "\r\n",
        "        #將結果 print 出來\r\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \\\r\n",
        "      (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\r\n",
        "      train_acc/train_val_set.__len__(), train_loss/train_val_set.__len__()))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/030] 20.60 sec(s) Train Acc: 0.291667 Loss: 0.031876\n",
            "[002/030] 20.58 sec(s) Train Acc: 0.390193 Loss: 0.027089\n",
            "[003/030] 20.61 sec(s) Train Acc: 0.455024 Loss: 0.024467\n",
            "[004/030] 20.61 sec(s) Train Acc: 0.502031 Loss: 0.022296\n",
            "[005/030] 20.56 sec(s) Train Acc: 0.538658 Loss: 0.020624\n",
            "[006/030] 20.54 sec(s) Train Acc: 0.573105 Loss: 0.019109\n",
            "[007/030] 20.63 sec(s) Train Acc: 0.604242 Loss: 0.017951\n",
            "[008/030] 20.61 sec(s) Train Acc: 0.628084 Loss: 0.016788\n",
            "[009/030] 20.59 sec(s) Train Acc: 0.647187 Loss: 0.015950\n",
            "[010/030] 20.60 sec(s) Train Acc: 0.672232 Loss: 0.014615\n",
            "[011/030] 20.65 sec(s) Train Acc: 0.696525 Loss: 0.013714\n",
            "[012/030] 20.61 sec(s) Train Acc: 0.713372 Loss: 0.012836\n",
            "[013/030] 20.61 sec(s) Train Acc: 0.734582 Loss: 0.011916\n",
            "[014/030] 20.59 sec(s) Train Acc: 0.753535 Loss: 0.011320\n",
            "[015/030] 20.57 sec(s) Train Acc: 0.756468 Loss: 0.010969\n",
            "[016/030] 20.59 sec(s) Train Acc: 0.770532 Loss: 0.010264\n",
            "[017/030] 20.56 sec(s) Train Acc: 0.786778 Loss: 0.009623\n",
            "[018/030] 20.59 sec(s) Train Acc: 0.799489 Loss: 0.009028\n",
            "[019/030] 20.61 sec(s) Train Acc: 0.817915 Loss: 0.008304\n",
            "[020/030] 20.59 sec(s) Train Acc: 0.826414 Loss: 0.007785\n",
            "[021/030] 20.56 sec(s) Train Acc: 0.836943 Loss: 0.007317\n",
            "[022/030] 20.58 sec(s) Train Acc: 0.852662 Loss: 0.006733\n",
            "[023/030] 20.61 sec(s) Train Acc: 0.856273 Loss: 0.006428\n",
            "[024/030] 20.59 sec(s) Train Acc: 0.869134 Loss: 0.005721\n",
            "[025/030] 20.54 sec(s) Train Acc: 0.878986 Loss: 0.005315\n",
            "[026/030] 20.62 sec(s) Train Acc: 0.884176 Loss: 0.005156\n",
            "[027/030] 20.58 sec(s) Train Acc: 0.889516 Loss: 0.004914\n",
            "[028/030] 20.60 sec(s) Train Acc: 0.909522 Loss: 0.004085\n",
            "[029/030] 20.60 sec(s) Train Acc: 0.906212 Loss: 0.004136\n",
            "[030/030] 20.57 sec(s) Train Acc: 0.915764 Loss: 0.003705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk3VF1_Ec7cv"
      },
      "source": [
        "test_set = ImgDataset(test_x, transform=test_transform)\r\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWO2jXn4c7cv"
      },
      "source": [
        "model_best.eval()\r\n",
        "prediction = []\r\n",
        "with torch.no_grad():\r\n",
        "    for i, data in enumerate(test_loader):\r\n",
        "        test_pred = model_best(data.cuda())\r\n",
        "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\r\n",
        "        for y in test_label:\r\n",
        "            prediction.append(y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctSBFaiwkq2j"
      },
      "source": [
        "#將結果寫入 csv 檔\r\n",
        "with open(\"predict2.csv\", 'w') as f:\r\n",
        "    f.write('Id,Category\\n')\r\n",
        "    for i, y in  enumerate(prediction):\r\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}